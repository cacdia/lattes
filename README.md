# AnÃ¡lise de CurrÃ­culos Lattes

## ğŸ“‹ ConteÃºdo

- [Sobre o Projeto](#-sobre-o-projeto)
- [Equipe](#-equipe)
- [Metodologia](#-metodologia)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [Primeiros Passos](#-primeiros-passos)
- [AnÃ¡lises Realizadas](#-anÃ¡lises-realizadas)
- [Resultados Principais](#-resultados-principais)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [SoluÃ§Ã£o de Problemas no Windows](#-soluÃ§Ã£o-de-problemas-no-windows)

## ğŸ“– Sobre o Projeto

Este projeto de CiÃªncia de Dados realiza uma anÃ¡lise abrangente dos currÃ­culos da Plataforma Lattes de docentes e pesquisadores do Centro de InformÃ¡tica (CI). A Plataforma Lattes, mantida pelo CNPq, Ã© uma base de dados rica em informaÃ§Ãµes sobre a produÃ§Ã£o acadÃªmica, profissional e intelectual de pesquisadores brasileiros.

## ğŸ‘¥ Equipe

- **Sarah Fernanda Calixto de AraÃºjo** â€” `20240011267`
- **Luiz Carlos Veloso de Araujo Lima Neto** â€” `20240102334`
- **Sofia Pontes LeitÃ£o de Lima** â€” `20240011285`
- **CauÃ£ Henrique Formiga de Lacerda** â€” `20240011089`

## ğŸ”¬ Metodologia

### 1. Coleta de Dados (Web Scraping)
Utilizamos a biblioteca **Playwright** para navegar automaticamente na Plataforma Lattes, capturando os currÃ­culos completos dos pesquisadores. Esta abordagem permite contornar limitaÃ§Ãµes de APIs e capturar dados estruturados diretamente das pÃ¡ginas web.

### 2. ExtraÃ§Ã£o e EstruturaÃ§Ã£o (Parsing)
ApÃ³s o download, um segundo script utiliza as bibliotecas **BeautifulSoup** e **Pandas** para fazer o parsing do conteÃºdo HTML. Ele extrai informaÃ§Ãµes-chave como dados bÃ¡sicos (nome, resumo), formaÃ§Ã£o acadÃªmica, projetos de pesquisa e redes de colaboraÃ§Ã£o (coautores e integrantes de projetos). Os dados sÃ£o entÃ£o consolidados e exportados em formatos estruturados como JSON, prontos para a anÃ¡lise.

### 3. AnÃ¡lise e Modelagem
Aplicamos tÃ©cnicas de:
- **AnÃ¡lise de Redes**: construÃ§Ã£o de grafos de coautoria com mÃ©tricas de centralidade
- **Clustering**: agrupamento temÃ¡tico usando TF-IDF e K-Means
- **AnÃ¡lise EstatÃ­stica**: correlaÃ§Ãµes entre formaÃ§Ã£o, experiÃªncia e produtividade
- **VisualizaÃ§Ã£o Interativa**: uso de Plotly e NetworkX para exploraÃ§Ã£o visual dos dados

## ğŸ”§ PrÃ©-requisitos

Certifique-se de instalar os seguintes programas antes de comeÃ§ar:

- **Visual Studio Code** ğŸ‘‰ [Download VSCode](https://code.visualstudio.com/)

- **Git** ğŸ‘‰ [Download Git](https://git-scm.com/downloads)

- **uv** O `uv` Ã© um gerenciador de pacotes e ambientes virtuais extremamente rÃ¡pido para Python. Instale utilizando o comando adequado ao seu sistema operacional:

  ```bash
  # Windows (PowerShell)
  powershell -ExecutionPolicy ByPass -c "irm [https://astral.sh/uv/install.ps1](https://astral.sh/uv/install.ps1) | iex"

  # macOS/Linux
  curl -LsSf [https://astral.sh/uv/install.sh](https://astral.sh/uv/install.sh) | sh

## ğŸš€ Primeiros Passos

Siga os passos abaixo para configurar rapidamente o projeto em sua mÃ¡quina.

### 1\. Clone o repositÃ³rio

```bash
git clone https://github.com/cacdia/lattes.git
cd lattes
```

### 2\. Configure o ambiente virtual

Crie o ambiente virtual e instale todas as dependÃªncias do projeto com um Ãºnico comando:

```bash
# Sincroniza o ambiente: cria o .venv e instala os pacotes listados no pyproject.toml
uv sync
```

### 3\. Configure o VSCode

Abra o projeto no Visual Studio Code:

```bash
code .
```

#### Instale as extensÃµes recomendadas

Ao abrir o projeto pela primeira vez:

- Uma notificaÃ§Ã£o aparecerÃ¡ sugerindo a instalaÃ§Ã£o das extensÃµes recomendadas.
- Clique em **Install All** ou em **Show Recommendations**.
- Alternativamente, pressione `Ctrl+Shift+X` (ou `Cmd+Shift+X` no macOS) e digite `@recommended` na barra de pesquisa.

#### Selecione o interpretador Python correto

Ã‰ crucial que o VSCode utilize o ambiente virtual (`.venv`) que o `uv` criou.

1.  Pressione `F1` (ou `Ctrl+Shift+P`)
2.  Digite **Python: Select Interpreter**
3.  Escolha o interpretador que tem **('.venv')** no nome. Ex: `"Python 3.13 ('.venv':venv)"`

### 4\. Execute o projeto

O projeto funciona em duas etapas principais: primeiro baixar os currÃ­culos, depois processÃ¡-los.

```bash
# Comando principal para executar o download
uv run scripts/download_profile.py --input data/professores_ci.csv
```

#### Exemplo com diretÃ³rio de saÃ­da personalizado

VocÃª tambÃ©m pode especificar onde os arquivos HTML dos currÃ­culos serÃ£o salvos com a flag `--output`.

```bash
# Salva os arquivos no diretÃ³rio 'meu_diretorio'
uv run scripts/download_profile.py --input data/professores_ci.csv --output meu_diretorio
```

ApÃ³s baixar os arquivos HTML, utilize o script parse_lattes.py para processÃ¡-los e gerar um arquivo consolidado com os dados extraÃ­dos.

O formato de saÃ­da (CSV ou JSON) Ã© definido pela extensÃ£o do arquivo que vocÃª especificar em --output.

#### Exemplo para saÃ­da em CSV:

```bash
# Processa os HTMLs da pasta 'meus_curriculos' e salva os dados em um arquivo CSV
uv run scripts/parse_profiles.py --input meu_diretorio --output data/professores.csv
```

#### Exemplo para saÃ­da em JSON:

```bash
# Processa os HTMLs e salva os dados em formato JSON
uv run scripts/parse_profiles.py --input meu_diretorio --output data/professores.json
```

### Execute as anÃ¡lises

Abra o Jupyter Lab e execute os notebooks na pasta `notebook/`:

```bash
uv run jupyter lab notebook/
```

Comece pelo [`notebook_relatorio.ipynb`](notebook/notebook_relatorio.ipynb) que contÃ©m as anÃ¡lises principais.

## ğŸ“Š AnÃ¡lises Realizadas

### 1. Ranking de Produtividade
- **Top pesquisadores por nÃºmero de publicaÃ§Ãµes**
- **Top pesquisadores por nÃºmero de coautorias**
- **AnÃ¡lise de correlaÃ§Ã£o entre produÃ§Ã£o e colaboraÃ§Ã£o**

### 2. Impacto da FormaÃ§Ã£o
- **RelaÃ§Ã£o entre nÃ­vel de formaÃ§Ã£o (Mestrado/Doutorado/PÃ³s-doc) e produtividade**
- **AnÃ¡lise estatÃ­stica com ANOVA e tratamento de outliers**
- **CorrelaÃ§Ã£o entre anos de experiÃªncia e produÃ§Ã£o cientÃ­fica**

### 3. AnÃ¡lise de Redes de ColaboraÃ§Ã£o
- **ConstruÃ§Ã£o de grafos de coautoria**
- **MÃ©tricas de centralidade (betweenness, eigenvector, grau)**
- **VisualizaÃ§Ã£o interativa com Plotly**
- **AnÃ¡lise especÃ­fica dos laboratÃ³rios ARIA e LAVID**

### 4. AnÃ¡lise de Redes de Coautoria entre Docentes do CI
- **ConstruÃ§Ã£o de grafo nÃ£o direcionado com nÃ³s = pesquisadores**
- **Arestas ponderadas pelo nÃºmero de publicaÃ§Ãµes em coautoria**
- **CÃ¡lculo de mÃ©tricas de centralidade (betweenness, eigenvector, grau)**
- **Filtragem para coautorias internas (apenas entre docentes do CI)**
- **VisualizaÃ§Ã£o interativa com layout forÃ§ado e cores por centralidade**
- **AnÃ¡lise especÃ­fica de subrede ARIA/LAVID com mapeamento por laboratÃ³rio**

### 5. Clustering TemÃ¡tico de TÃ­tulos de PublicaÃ§Ãµes
- **PrÃ©-processamento de texto com remoÃ§Ã£o de stopwords em portuguÃªs**
- **VetorizaÃ§Ã£o TF-IDF de tÃ­tulos de publicaÃ§Ãµes (3.000 features)**
- **DeterminaÃ§Ã£o do nÃºmero Ã³timo de clusters usando mÃºltiplas mÃ©tricas**:
  - MÃ©todo do Cotovelo (WCSS)
  - Coeficiente de Silhueta
  - Ãndice Calinski-Harabasz
  - Ãndice Davies-Bouldin
- **AplicaÃ§Ã£o de K-Means com validaÃ§Ã£o por ranking combinado**
- **VisualizaÃ§Ã£o 2D e 3D dos clusters usando PCA**
- **IdentificaÃ§Ã£o de 4 clusters principais de Ã¡reas temÃ¡ticas**

## ğŸ“ Estrutura do Projeto

```
lattes/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ ISSUE_TEMPLATE/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ professores_ci.csv          # Lista de entrada dos professores
â”‚   â”œâ”€â”€ professores.json            # Dados consolidados (JSON)
â”‚   â”œâ”€â”€ prof_labs.csv               # Mapeamento professor â†” laboratÃ³rio
â”‚   â””â”€â”€ titulos_producoes.json      # TÃ­tulos para anÃ¡lise de clustering
â”œâ”€â”€ professores_perfil_html/        # HTMLs dos currÃ­culos coletados
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ notebook_relatorio.ipynb    # Notebook principal com anÃ¡lises
â”‚   â”œâ”€â”€ analysis.ipynb              # AnÃ¡lises exploratÃ³rias adicionais
â”‚   â”œâ”€â”€ laboratorios.ipynb          # AnÃ¡lises por laboratÃ³rio
â”‚   â”œâ”€â”€ proximidade_titulos.ipynb   # AnÃ¡lise de similaridade de tÃ­tulos
â”‚   â””â”€â”€ utils_lattes.py             # FunÃ§Ãµes utilitÃ¡rias
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_profile.py         # Script para coleta dos currÃ­culos
â”‚   â””â”€â”€ parse_profiles.py           # Script para parsing dos HTMLs
â”œâ”€â”€ src/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ .vscode/                        # ConfiguraÃ§Ãµes do VS Code
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pyproject.toml                  # DependÃªncias e metadados
â”œâ”€â”€ README.md
â”œâ”€â”€ ruff.toml                       # ConfiguraÃ§Ãµes de formataÃ§Ã£o
â””â”€â”€ uv.lock                         # Lock file para dependÃªncias
```

## ğŸªŸ SoluÃ§Ã£o de Problemas no Windows

Caso encontre problemas de permissÃ£o ao executar scripts no PowerShell (comum ao instalar o uv), execute o seguinte comando para permitir a execuÃ§Ã£o de scripts assinados:

```bash
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins acadÃªmicos como parte da disciplina de IntroduÃ§Ã£o Ã  CiÃªncia de Dados, ministrada pelo professor Yuri Malheiros.

---

**Nota**: Para reproduzir completamente as anÃ¡lises, execute primeiro os scripts de coleta e parsing, depois abra os notebooks na ordem sugerida.
