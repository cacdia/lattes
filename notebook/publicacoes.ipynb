{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3691c62f",
   "metadata": {},
   "source": [
    "# Deduplicação de Publicações Acadêmicas\n",
    "\n",
    "Este notebook realiza a deduplicação de publicações acadêmicas dos professores, criando o arquivo `publicacoes_unificadas.json` na pasta `data`.\n",
    "\n",
    "O processo inclui:\n",
    "1. Carregamento dos dados dos professores\n",
    "2. Normalização de nomes e títulos\n",
    "3. Agrupamento de publicações similares\n",
    "4. Identificação de colaborações\n",
    "5. Geração do arquivo JSON unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a6d16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import uuid\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd9e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de professores carregados: 67\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados dos professores\n",
    "with open(\"../data/professores.json\", encoding=\"utf-8\") as f:\n",
    "    professores = json.load(f)\n",
    "\n",
    "print(f\"Total de professores carregados: {len(professores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8263d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name_for_comparison(name):\n",
    "    \"\"\"Normaliza nomes para comparação, removendo acentos e caracteres especiais.\"\"\"\n",
    "    if not name or not isinstance(name, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove acentos\n",
    "    name = unicodedata.normalize(\"NFD\", name)\n",
    "    name = \"\".join(char for char in name if unicodedata.category(char) != \"Mn\")\n",
    "\n",
    "    # Converte para maiúsculo e remove pontuação\n",
    "    name = name.upper()\n",
    "    name = re.sub(r\"[^\\w\\s]\", \" \", name)\n",
    "    name = \" \".join(name.split())\n",
    "    return name\n",
    "\n",
    "\n",
    "def extract_name_variations(name):\n",
    "    \"\"\"Extrai variações de um nome para matching.\"\"\"\n",
    "    if not name:\n",
    "        return set()\n",
    "\n",
    "    normalized = normalize_name_for_comparison(name)\n",
    "    variations = {normalized}\n",
    "    variations.add(normalized.replace(\" \", \"\"))\n",
    "\n",
    "    parts = normalized.split()\n",
    "    if len(parts) > 1:\n",
    "        # Iniciais\n",
    "        initials = \"\".join([part[0] for part in parts if part])\n",
    "        variations.add(initials)\n",
    "\n",
    "    # Primeiro e último nome\n",
    "    if len(parts) > 2:\n",
    "        first_last = f\"{parts[0]} {parts[-1]}\"\n",
    "        variations.add(first_last)\n",
    "        variations.add(first_last.replace(\" \", \"\"))\n",
    "\n",
    "    return variations\n",
    "\n",
    "\n",
    "def create_comprehensive_name_mapping(professors_data):\n",
    "    \"\"\"Cria mapeamento abrangente de nomes para identificação de autores.\"\"\"\n",
    "    name_mapping = {}\n",
    "    professor_info = {}\n",
    "\n",
    "    for prof in professors_data:\n",
    "        identificacao = prof.get(\"identificacao\", {})\n",
    "        nome_principal = identificacao.get(\"nome\", \"\")\n",
    "        lattes_id = identificacao.get(\"lattes_id\", \"\")\n",
    "        nomes_citacao = identificacao.get(\"nomes_citacao\", [])\n",
    "\n",
    "        if not nome_principal:\n",
    "            continue\n",
    "\n",
    "        professor_info[lattes_id] = {\n",
    "            \"nome_principal\": nome_principal,\n",
    "            \"nomes_citacao\": nomes_citacao,\n",
    "        }\n",
    "\n",
    "        # Mapear nome principal\n",
    "        normalized_main = normalize_name_for_comparison(nome_principal)\n",
    "        name_mapping[normalized_main] = {\n",
    "            \"nome_principal\": nome_principal,\n",
    "            \"lattes_id\": lattes_id,\n",
    "        }\n",
    "\n",
    "        # Mapear variações do nome principal\n",
    "        for variation in extract_name_variations(nome_principal):\n",
    "            name_mapping[variation] = {\n",
    "                \"nome_principal\": nome_principal,\n",
    "                \"lattes_id\": lattes_id,\n",
    "            }\n",
    "\n",
    "        # Mapear nomes de citação\n",
    "        for nome_citacao in nomes_citacao:\n",
    "            if nome_citacao and isinstance(nome_citacao, str):\n",
    "                normalized_citation = normalize_name_for_comparison(nome_citacao)\n",
    "                name_mapping[normalized_citation] = {\n",
    "                    \"nome_principal\": nome_principal,\n",
    "                    \"lattes_id\": lattes_id,\n",
    "                }\n",
    "\n",
    "                # Mapear variações dos nomes de citação\n",
    "                for variation in extract_name_variations(nome_citacao):\n",
    "                    name_mapping[variation] = {\n",
    "                        \"nome_principal\": nome_principal,\n",
    "                        \"lattes_id\": lattes_id,\n",
    "                    }\n",
    "\n",
    "    return name_mapping, professor_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92bcbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_author_matching(author_name, name_mapping):\n",
    "    \"\"\"Realiza matching avançado de autores usando o mapeamento de nomes.\"\"\"\n",
    "    if not author_name or not isinstance(author_name, str):\n",
    "        return None\n",
    "\n",
    "    normalized_author = normalize_name_for_comparison(author_name)\n",
    "\n",
    "    # Busca direta\n",
    "    if normalized_author in name_mapping:\n",
    "        return name_mapping[normalized_author]\n",
    "\n",
    "    # Busca sem espaços\n",
    "    no_spaces = normalized_author.replace(\" \", \"\")\n",
    "    if no_spaces in name_mapping:\n",
    "        return name_mapping[no_spaces]\n",
    "\n",
    "    # Busca por primeiro e último nome\n",
    "    author_parts = normalized_author.split()\n",
    "    if len(author_parts) >= 2:\n",
    "        first_last = f\"{author_parts[0]} {author_parts[-1]}\"\n",
    "        if first_last in name_mapping:\n",
    "            return name_mapping[first_last]\n",
    "\n",
    "        first_last_no_space = first_last.replace(\" \", \"\")\n",
    "        if first_last_no_space in name_mapping:\n",
    "            return name_mapping[first_last_no_space]\n",
    "\n",
    "    # Busca por partes significativas comuns\n",
    "    for mapped_name, prof_info in name_mapping.items():\n",
    "        mapped_parts = set(mapped_name.split())\n",
    "        author_parts_set = set(author_parts)\n",
    "\n",
    "        common_parts = mapped_parts.intersection(author_parts_set)\n",
    "        if len(common_parts) >= 2:\n",
    "            # Verificar se há partes significativas (> 3 caracteres)\n",
    "            significant_common = [part for part in common_parts if len(part) > 3]\n",
    "            if significant_common:\n",
    "                return prof_info\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed084d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Normaliza texto removendo acentos e caracteres especiais.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    text = unicodedata.normalize(\"NFD\", text)\n",
    "    text = \"\".join(char for char in text if unicodedata.category(char) != \"Mn\")\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_main_title(full_title):\n",
    "    \"\"\"Extrai o título principal de um título completo.\"\"\"\n",
    "    if not full_title:\n",
    "        return \"\"\n",
    "\n",
    "    # Divide por pontos seguidos de espaço\n",
    "    parts = re.split(r\"\\.\\s+\", full_title)\n",
    "\n",
    "    # Procura por indicadores de informações bibliográficas\n",
    "    for i, part in enumerate(parts):\n",
    "        if re.search(\n",
    "            r\"\\b(v\\.|vol\\.|volume|p\\.|pp\\.|páginas|anais|proceedings|revista)\",\n",
    "            part,\n",
    "            re.IGNORECASE,\n",
    "        ):\n",
    "            return \". \".join(parts[:i]).strip()\n",
    "        if re.search(r\"\\b\\d{4}\\s*\\.$\", part):\n",
    "            return \". \".join(parts[: i + 1]).strip()\n",
    "\n",
    "    # Se a primeira parte é significativa, use-a\n",
    "    if len(parts) > 1 and len(parts[0].strip()) > 20:\n",
    "        return parts[0].strip()\n",
    "\n",
    "    return full_title.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba59bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_publications(professors_data):\n",
    "    \"\"\"Extrai todas as publicações dos professores.\"\"\"\n",
    "    publications = []\n",
    "\n",
    "    for professor in professors_data:\n",
    "        prof_name = professor.get(\"identificacao\", {}).get(\"nome\", \"Desconhecido\")\n",
    "        prof_id = professor.get(\"identificacao\", {}).get(\"lattes_id\", \"\")\n",
    "\n",
    "        for pub in professor.get(\"producao_bibliografica\", []):\n",
    "            titulo_completo = pub.get(\"titulo\", \"\").strip()\n",
    "            if titulo_completo:\n",
    "                titulo_principal = extract_main_title(titulo_completo)\n",
    "                publications.append(\n",
    "                    {\n",
    "                        \"professor\": prof_name,\n",
    "                        \"professor_id\": prof_id,\n",
    "                        \"titulo_completo\": titulo_completo,\n",
    "                        \"titulo_principal\": titulo_principal,\n",
    "                        \"titulo_normalizado\": normalize_text(titulo_principal),\n",
    "                        \"autores\": pub.get(\"autores\", []),\n",
    "                        \"ano\": pub.get(\"ano\", \"\"),\n",
    "                        \"revista\": pub.get(\"revista\"),\n",
    "                        \"doi\": pub.get(\"doi\"),\n",
    "                        \"paginas\": pub.get(\"paginas\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return publications\n",
    "\n",
    "\n",
    "def group_publications_by_similarity(publications):\n",
    "    \"\"\"Agrupa publicações por similaridade de título.\"\"\"\n",
    "    title_groups = defaultdict(list)\n",
    "    for pub in publications:\n",
    "        title_groups[pub[\"titulo_normalizado\"]].append(pub)\n",
    "    return list(title_groups.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57359f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_with_enhanced_names(professores, name_mapping):\n",
    "    \"\"\"Realiza deduplicação avançada com mapeamento de nomes melhorado.\"\"\"\n",
    "    publicacoes = extract_all_publications(professores)\n",
    "    grupos = group_publications_by_similarity(publicacoes)\n",
    "    publicacoes_unicas = []\n",
    "    total_colaboracoes = 0\n",
    "\n",
    "    for grupo in grupos:\n",
    "        # Escolhe a publicação com mais autores como representativa\n",
    "        def count_authors(pub):\n",
    "            autores = pub.get(\"autores\", \"\")\n",
    "            if isinstance(autores, str):\n",
    "                return len(autores.split(\";\"))\n",
    "            elif isinstance(autores, list):\n",
    "                return len(autores)\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        publicacao_repr = max(grupo, key=count_authors)\n",
    "        unique_id = str(uuid.uuid4())\n",
    "        professores_associados = set()\n",
    "        nomes_autores_originais = set()\n",
    "\n",
    "        # Processar cada publicação do grupo\n",
    "        for pub in grupo:\n",
    "            if \"professor\" in pub:\n",
    "                professores_associados.add(pub[\"professor\"])\n",
    "\n",
    "            autores = pub.get(\"autores\", \"\")\n",
    "            if isinstance(autores, str):\n",
    "                autores_list = autores.split(\";\")\n",
    "            elif isinstance(autores, list):\n",
    "                autores_list = autores\n",
    "            else:\n",
    "                autores_list = []\n",
    "\n",
    "            # Processar cada autor\n",
    "            for autor in autores_list:\n",
    "                autor = str(autor).strip()\n",
    "                if autor:\n",
    "                    nomes_autores_originais.add(autor)\n",
    "                    match = advanced_author_matching(autor, name_mapping)\n",
    "                    if match:\n",
    "                        professores_associados.add(match[\"nome_principal\"])\n",
    "\n",
    "        eh_colaboracao = len(professores_associados) > 1\n",
    "        if eh_colaboracao:\n",
    "            total_colaboracoes += 1\n",
    "\n",
    "        publicacao_unica = {\n",
    "            \"id_unico\": unique_id,\n",
    "            \"titulo\": publicacao_repr.get(\"titulo\", \"\"),\n",
    "            \"ano\": publicacao_repr.get(\"ano\", \"\"),\n",
    "            \"autores_originais\": list(nomes_autores_originais),\n",
    "            \"professores_identificados\": list(professores_associados),\n",
    "            \"eh_colaboracao\": eh_colaboracao,\n",
    "            \"num_professores\": len(professores_associados),\n",
    "            \"publicacoes_originais\": len(grupo),\n",
    "            \"detalhes_originais\": grupo,\n",
    "        }\n",
    "\n",
    "        publicacoes_unicas.append(publicacao_unica)\n",
    "\n",
    "    return publicacoes_unicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aee9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simplified_json(publicacoes_unicas):\n",
    "    \"\"\"Cria versão simplificada do JSON para o arquivo final.\"\"\"\n",
    "    publicacoes_simplificadas = []\n",
    "\n",
    "    for pub in publicacoes_unicas:\n",
    "        titulo = \"\"\n",
    "        if \"detalhes_originais\" in pub and pub[\"detalhes_originais\"]:\n",
    "            original = pub[\"detalhes_originais\"][0]\n",
    "            titulo = (\n",
    "                original.get(\"titulo_completo\")\n",
    "                or original.get(\"titulo_principal\")\n",
    "                or original.get(\"titulo\")\n",
    "                or \"\"\n",
    "            )\n",
    "\n",
    "        publicacao_simples = {\n",
    "            \"id_unico\": pub[\"id_unico\"],\n",
    "            \"titulo\": titulo,\n",
    "            \"professores\": pub[\"professores_identificados\"],\n",
    "        }\n",
    "        publicacoes_simplificadas.append(publicacao_simples)\n",
    "\n",
    "    return publicacoes_simplificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbbb373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando mapeamento de nomes...\n",
      "Mapeamento criado com 1670 entradas\n",
      "\n",
      "Realizando deduplicação...\n",
      "Encontradas 5002 publicações únicas\n",
      "Colaborações identificadas: 1997\n",
      "Publicações individuais: 3005\n"
     ]
    }
   ],
   "source": [
    "# Executar o processo de deduplicação\n",
    "print(\"Criando mapeamento de nomes...\")\n",
    "name_mapping, professor_info = create_comprehensive_name_mapping(professores)\n",
    "print(f\"Mapeamento criado com {len(name_mapping)} entradas\")\n",
    "\n",
    "print(\"\\nRealizando deduplicação...\")\n",
    "publicacoes_unicas = deduplicate_with_enhanced_names(professores, name_mapping)\n",
    "print(f\"Encontradas {len(publicacoes_unicas)} publicações únicas\")\n",
    "\n",
    "# Contar colaborações\n",
    "colaboracoes = [pub for pub in publicacoes_unicas if pub[\"eh_colaboracao\"]]\n",
    "print(f\"Colaborações identificadas: {len(colaboracoes)}\")\n",
    "print(f\"Publicações individuais: {len(publicacoes_unicas) - len(colaboracoes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b36b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando arquivo JSON simplificado...\n",
      "Arquivo salvo em: ../data/publicacoes_unificadas.json\n",
      "Total de publicações no arquivo: 5002\n",
      "\n",
      "==================================================\n",
      "ESTATÍSTICAS FINAIS\n",
      "==================================================\n",
      "Total de publicações processadas: 5382\n",
      "Publicações únicas após deduplicação: 5002\n",
      "Taxa de deduplicação: 7.1%\n",
      "\n",
      "Exemplo de publicação:\n",
      "  ID: abce666d-53be-44af-9f80-de06e258f282\n",
      "  Título: Supporting the choice of the best-fit agile model using FITradeoff. PESQUISA OPERACIONAL (IMPRESSO) ...\n",
      "  Professores: ['Adriana Carla Damasceno']\n"
     ]
    }
   ],
   "source": [
    "# Criar arquivo JSON simplificado\n",
    "print(\"Criando arquivo JSON simplificado...\")\n",
    "publicacoes_json_simples = create_simplified_json(publicacoes_unicas)\n",
    "\n",
    "# Salvar o arquivo publicacoes_unificadas.json\n",
    "output_file = \"../data/publicacoes_unificadas.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(publicacoes_json_simples, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Arquivo salvo em: {output_file}\")\n",
    "print(f\"Total de publicações no arquivo: {len(publicacoes_json_simples)}\")\n",
    "\n",
    "# Exibir algumas estatísticas\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ESTATÍSTICAS FINAIS\")\n",
    "print(\"=\" * 50)\n",
    "print(\n",
    "    f\"Total de publicações processadas: {sum(len(p.get('producao_bibliografica', [])) for p in professores)}\"\n",
    ")\n",
    "print(f\"Publicações únicas após deduplicação: {len(publicacoes_json_simples)}\")\n",
    "print(\n",
    "    f\"Taxa de deduplicação: {(1 - len(publicacoes_json_simples) / sum(len(p.get('producao_bibliografica', [])) for p in professores)) * 100:.1f}%\"\n",
    ")\n",
    "\n",
    "# Exemplo de publicação\n",
    "if publicacoes_json_simples:\n",
    "    print(\"\\nExemplo de publicação:\")\n",
    "    exemplo = publicacoes_json_simples[0]\n",
    "    print(f\"  ID: {exemplo.get('id_unico', 'N/A')}\")\n",
    "    print(f\"  Título: {exemplo.get('titulo', 'N/A')[:100]}...\")\n",
    "    print(f\"  Professores: {exemplo.get('professores', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4263c",
   "metadata": {},
   "source": [
    "## Verificação do Arquivo Gerado\n",
    "\n",
    "O arquivo `publicacoes_unificadas.json` foi criado na pasta `data` com a estrutura:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"id_unico\": \"uuid-único\",\n",
    "    \"titulo\": \"Título da publicação\",\n",
    "    \"professores\": [\"Nome Professor 1\", \"Nome Professor 2\", ...]\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "Este arquivo contém:\n",
    "- Publicações deduplicadas\n",
    "- Identificação de colaborações entre professores\n",
    "- IDs únicos para cada publicação\n",
    "- Lista de professores envolvidos em cada publicação"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-starter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
